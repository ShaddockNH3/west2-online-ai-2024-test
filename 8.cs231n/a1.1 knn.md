### 作业思路讲解

第一个函数至第三个函数需要实现欧氏距离，公式依托：

$$  
d(x_{\text{test}}, x_i) = \sqrt{\sum_{j=1}^D (x_{\text{test}}^{(j)} - x_i^{(j)})^2}  
$$


第一个函数：

```python
    def compute_distances_two_loops(self, X):
        num_test = X.shape[0]
        num_train = self.X_train.shape[0]
        dists = np.zeros((num_test, num_train))
        for i in range(num_test):
            for j in range(num_train):
                dists[i,j]=np.sqrt(np.sum((X[i]-self.X_train[j])**2))
        return dists
```

第二个函数：

```python
    def compute_distances_one_loop(self, X):
        num_test = X.shape[0]
        num_train = self.X_train.shape[0]
        dists = np.zeros((num_test, num_train))
        for i in range(num_test):
            dists[i,:]=np.sqrt(np.sum((self.X_train-X[i])**2,axis=1))
        return dists
```

这一行的意思就是按照y轴累计

第三个函数的实现依托于数学公式：

$$  
\text{Dists} = \sqrt{ \underbrace{\sum X_{\text{test}}^2}_{\text{Test}^2} + \underbrace{\sum X_{\text{train}}^2}_{\text{Train}^2} - 2 \cdot X_{\text{test}} X_{\text{train}}^\top }  
$$
```python
    def compute_distances_no_loops(self, X):
        num_test = X.shape[0]
        num_train = self.X_train.shape[0]
        dists = np.zeros((num_test, num_train))
        test_sq=np.sum(X**2,axis=1).reshape(-1,1) #这里转换为一个列向量
        train_sq=np.sum(self.X_train**2,axis=1)  #这里已经是行向量了
        dot_product=X@self.X_train.T        #这里就是矩阵的内积
        dists=np.sqrt(test_sq+train_sq-2*dot_product) #根据数学原理
        return dists
```

第四个函数实现预测功能，基于knn算法，根据测试样本与训练样本的距离矩阵预测测试集的分类标签。核心逻辑是通过统计最近k个邻居的标签频次，选择出现次数最多的类别作为预测结果。

整体思路就是：

测试样本i → 距离排序 → 取k近邻 → 统计标签频次 → 按频次+标签值排序 → 取最高频标签

```python
    def predict_labels(self, dists, k=1):
        num_test = dists.shape[0]
        y_pred = np.zeros(num_test)
        for i in range(num_test):
            closest_y = []

            sorted_i=np.argsort(dists[i,:])
            closest_y=self.y_train[sorted_i[:k]]

            unique_labels, counts = np.unique(closest_y, return_counts=True)

            sorted_indices = np.argsort(counts)[::-1]
            sorted_indices = np.argsort(np.column_stack((-counts, unique_labels)), axis=0)[:, 0]
            
            sorted_labels = unique_labels[sorted_indices]

            y_pred[i]=sorted_labels[0]

        return y_pred
```

第五个函数是要求实现k最邻分类器，也就是预测k次，然后取最好的那个。

其实很简单，就是训练之后然后选择最大的那个。

将已知随机分成五类，然后屏蔽其中一类，训练其他四类，最后在最后一类上进行测试

```python
num_folds = 5
k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]

X_train_folds = []
y_train_folds = []

X_train_folds=np.array_split(X_train,num_folds)
y_train_folds=np.array_split(y_train,num_folds)

k_to_accuracies = {}

for k in k_choices:
  temp=[]
  for i in range(num_folds):
    x_val=X_train_folds[i]
    y_val=y_train_folds[i]

    X_train_temp=np.concatenate(X_train_folds[:i]+X_train_folds[i+1:])
    y_train_temp=np.concatenate(y_train_folds[:i]+y_train_folds[i+1:])

    knn=KNearestNeighbor()
    knn.train(X_train_temp, y_train_temp)
    y_pred=knn.predict(x_val,k)

    num_correct = np.sum(y_pred == y_val)
    accuracy = float(num_correct) / len(y_val)
    temp.append(accuracy)

  k_to_accuracies[k]=temp

# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

# Print out the computed accuracies
for k in sorted(k_to_accuracies):
    for accuracy in k_to_accuracies[k]:
        print('k = %d, accuracy = %f' % (k, accuracy))
```