knn-liner-loss-sgd-

## knn

### **ğŸ“š k-æœ€è¿‘é‚»ç®—æ³•ï¼ˆKNNï¼‰æ·±åº¦è§£æä¸ä¼˜åŒ–æŒ‡å—**

---

#### **ğŸŒ‰ è¯­ä¹‰é¸¿æ²Ÿï¼šè®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŒ‘æˆ˜**
1. **å®šä¹‰**  
   - **è®¡ç®—æœºè§†è§’**ï¼šå›¾åƒæ˜¯åƒç´ å€¼çš„çŸ©é˜µï¼ˆå¦‚ 32x32x3 çš„æ•°å€¼é˜µåˆ—ï¼‰  
   - **äººç±»è§†è§’**ï¼šç†è§£å›¾åƒä¸­çš„ç‰©ä½“ã€åœºæ™¯å’Œè¯­ä¹‰ï¼ˆå¦‚"è¿™æ˜¯ä¸€åªçŒ«åœ¨æ²™å‘ä¸Š"ï¼‰  
   - **é¸¿æ²Ÿæœ¬è´¨**ï¼šä½çº§åƒç´ ç‰¹å¾ä¸é«˜çº§è¯­ä¹‰ç†è§£ä¹‹é—´çš„æ–­å±‚  

2. **KNNçš„åº”å¯¹ç­–ç•¥**  
   - **ç›´æ¥æ¯”å¯¹åƒç´ ç›¸ä¼¼æ€§**ï¼šå‡è®¾ç›¸ä¼¼åƒç´ æ¨¡å¼çš„å›¾åƒå…·æœ‰ç›¸åŒè¯­ä¹‰  
   - **å±€é™æ€§æ¡ˆä¾‹**ï¼š  
     - åŒä¸€åªçŒ«åœ¨ä¸åŒå…‰ç…§ä¸‹ï¼Œåƒç´ å·®å¼‚å¯èƒ½å¤§äºä¸åŒç‰©ä½“çš„å·®å¼‚  
     - æ—‹è½¬åçš„å›¾åƒä¸åŸå§‹å›¾åƒçš„L2è·ç¦»å¯èƒ½æå¤§  

```python
# è¯­ä¹‰é¸¿æ²Ÿç¤ºä¾‹ï¼šåŒä¸€ç‰©ä½“çš„ä¸åŒåƒç´ è¡¨ç°
cat_image1 = æ—¥å…‰ä¸‹çš„çŒ«ï¼ˆåƒç´ æ˜äº®ï¼‰  
cat_image2 = é˜´å½±ä¸­çš„çŒ«ï¼ˆåƒç´ æš—æ·¡ï¼‰  
dog_image = æ—¥å…‰ä¸‹çš„ç‹—ï¼ˆåƒç´ æ˜äº®ï¼‰  

d(cat1, cat2) = é«˜è·ç¦»ï¼ˆåƒç´ å·®å¼‚å¤§ä½†è¯­ä¹‰ç›¸åŒï¼‰  
d(cat1, dog) = ä½è·ç¦»ï¼ˆåƒç´ ç›¸ä¼¼ä½†è¯­ä¹‰ä¸åŒï¼‰
```

---

#### **ğŸš€ æ•°æ®é©±åŠ¨æ–¹æ³•çš„é©å‘½æ€§**
1. **ä¸ä¼ ç»Ÿè§„åˆ™æ–¹æ³•çš„å¯¹æ¯”**  

| æ–¹æ³•   | æ ¸å¿ƒ               | æ‰©å±•æ€§           | æ¡ˆä¾‹         |
| ---- | ---------------- | ------------- | ---------- |
| è§„åˆ™æ–¹æ³• | æ‰‹å·¥å®šä¹‰ç‰¹å¾ï¼ˆå¦‚"çŒ«æœ‰å°–è€³æœµ"ï¼‰ | å·®ï¼ˆéœ€ä¸ºæ¯ä¸ªç±»åˆ«é‡æ–°è®¾è®¡ï¼‰ | æ—©æœŸOCRè¯†åˆ«    |
| æ•°æ®é©±åŠ¨ | ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ ç‰¹å¾       | å¼ºï¼ˆåŒä¸€æ¡†æ¶å¤„ç†ä¸åŒä»»åŠ¡ï¼‰ | ImageNetåˆ†ç±» |

2. **KNNçš„æ•°æ®é©±åŠ¨æµç¨‹**  
   ```mermaid
   graph LR
   A[è®­ç»ƒé˜¶æ®µ] --> B[å­˜å‚¨æ‰€æœ‰è®­ç»ƒæ•°æ®]
   C[é¢„æµ‹é˜¶æ®µ] --> D[è®¡ç®—æµ‹è¯•æ ·æœ¬ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„è·ç¦»]
   D --> E[é€‰æ‹©Kä¸ªæœ€è¿‘é‚»]
   E --> F[æŠ•ç¥¨å†³å®šç±»åˆ«]
   ```

---

#### **ğŸ“ è·ç¦»åº¦é‡çš„å¤šç»´æˆ˜åœº**
1. **L1ï¼ˆæ›¼å“ˆé¡¿è·ç¦»ï¼‰æ·±åº¦è§£æ**  
   - **å‡ ä½•æ„ä¹‰**ï¼šåœ¨äºŒç»´ç©ºé—´ä¸­å½¢æˆè±å½¢ç­‰é«˜çº¿  
   - **é€‚ç”¨åœºæ™¯**ï¼š  
     - ç‰¹å¾å…·æœ‰ä¸åŒé‡è¦æ€§æ—¶ï¼ˆå¦‚æŸäº›åƒç´ å¯¹åˆ†ç±»æ›´å…³é”®ï¼‰  
     - å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼ˆå› ä½¿ç”¨ç»å¯¹å€¼ï¼‰  
   - **å›¾åƒæ¯”å¯¹å®éªŒ**ï¼š  
     ```python
     # è®¡ç®—ä¸¤å¹…å›¾åƒçš„L1è·ç¦»
     def l1_distance(img1, img2):
         return np.sum(np.abs(img1 - img2))
     
     # å®éªŒï¼šæ—‹è½¬10åº¦çš„å›¾åƒ vs åŸå§‹å›¾åƒ
     rotated_cat = rotate(original_cat, 10)
     print(l1_distance(original_cat, rotated_cat))  # è¾“å‡ºè¾ƒå¤§å€¼
     ```

2. **L2ï¼ˆæ¬§å¼è·ç¦»ï¼‰ç‰¹æ€§åˆ†æ**  
   - **å‡ ä½•æ„ä¹‰**ï¼šå½¢æˆåœ†å½¢ç­‰é«˜çº¿ï¼Œå„æ–¹å‘å‡åŒ€æ•æ„Ÿ  
   - **æ•°å­¦æ€§è´¨**ï¼š  
     - æ»¡è¶³ä¸‰è§’ä¸ç­‰å¼ï¼šd(a,c) â‰¤ d(a,b) + d(b,c)  
     - å¯¹å¼‚å¸¸å€¼æ•æ„Ÿï¼ˆå¹³æ–¹æ”¾å¤§å·®å¼‚ï¼‰  
   - **ä¼˜åŒ–æŠ€å·§**ï¼š  
     - å¯çœç•¥å¼€å¹³æ–¹è¿ç®—ï¼ˆæ¯”è¾ƒè·ç¦»å¤§å°æ—¶ç»“æœä¸å˜ï¼‰  
     - æå‰å½’ä¸€åŒ–åƒç´ å€¼åˆ°[0,1]èŒƒå›´  

3. **è·ç¦»åº¦é‡é€‰æ‹©ç­–ç•¥**

| æƒ…å†µ           | æ¨èåº¦é‡          | åŸå›           |
| ------------ | ------------- | ----------- |
| ç‰¹å¾ç¨€ç–ï¼ˆå¤šæ•°åƒç´ ä¸º0ï¼‰ | L1            | å¯¹é›¶å€¼ä¸æ•æ„Ÿ      |
| éœ€è¦æ—‹è½¬ä¸å˜æ€§      | æ”¹è¿›çš„L2ï¼ˆéœ€é…åˆé¢„å¤„ç†ï¼‰ | å¹³æ»‘å“åº”        |
| é¢œè‰²ç›´æ–¹å›¾æ¯”è¾ƒ      | ä½™å¼¦ç›¸ä¼¼åº¦         | å…³æ³¨åˆ†å¸ƒå½¢çŠ¶è€Œéç»å¯¹å€¼ |

---

#### **ğŸ›ï¸ è¶…å‚æ•°è°ƒä¼˜ï¼šç§‘å­¦ä¸è‰ºæœ¯çš„ç»“åˆ**
4. **Kå€¼é€‰æ‹©çš„é»„é‡‘æ³•åˆ™**  
   - **å¥‡å¶è§„åˆ™**ï¼šé€‰æ‹©å¥‡æ•°Kå€¼é¿å…å¹³ç¥¨ï¼ˆå°¤å…¶äºŒåˆ†ç±»æ—¶ï¼‰  
   - **ç»éªŒå…¬å¼**ï¼šK â‰ˆ sqrt(n_samples)ï¼ˆå–æœ€æ¥è¿‘çš„å¥‡æ•°ï¼‰  
   - **è‡ªé€‚åº”ç­–ç•¥**ï¼š  
     - å°æ•°æ®é›†ï¼šK=3æˆ–5  
     - å¤§æ•°æ®é›†ï¼šK=11æˆ–15  

5. **è·ç¦»æƒé‡ä¼˜åŒ–**  
   - **çº¿æ€§åŠ æƒ**ï¼š1/(distance + Îµ)ï¼ˆÎµé˜²æ­¢é™¤é›¶ï¼‰  
   - **æŒ‡æ•°è¡°å‡**ï¼šexp(-distance)  
   - **ä»£ç å®ç°**ï¼š  
     ```python
     def weighted_vote(neighbors, distances):
         weights = 1 / (distances + 1e-5)
         class_weights = defaultdict(float)
         for i, (label, _) in enumerate(neighbors):
             class_weights[label] += weights[i]
         return max(class_weights, key=class_weights.get)
     ```

6. **é«˜çº§éªŒè¯ç­–ç•¥**  
   - **åµŒå¥—äº¤å‰éªŒè¯**ï¼š  
     ```mermaid
     graph TD
     A[åŸå§‹æ•°æ®] --> B[å¤–å±‚åˆ’åˆ†ï¼š5æŠ˜]
     B --> C{æ¯æŠ˜ä½œä¸ºæµ‹è¯•é›†}
     C --> D[å‰©ä½™æ•°æ®åˆ’åˆ†ï¼š3æŠ˜]
     D --> E[å†…å±‚è®­ç»ƒ/éªŒè¯]
     E --> F[é€‰æ‹©æœ€ä½³å‚æ•°]
     F --> G[å¤–å±‚è¯„ä¼°]
     ```
   - **è´å¶æ–¯ä¼˜åŒ–**ï¼šä½¿ç”¨é«˜æ–¯è¿‡ç¨‹å¯»æ‰¾æœ€ä¼˜è¶…å‚æ•°ç»„åˆ  

---

#### **ğŸ”§ å·¥ç¨‹ä¼˜åŒ–ï¼šçªç ´KNNçš„æ€§èƒ½ç“¶é¢ˆ**
7. **è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰ç®—æ³•**  
   - **FLANNåº“**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç®—æ³•ï¼ˆKDæ ‘ã€K-meansæ ‘ç­‰ï¼‰  
   - **å±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼ˆLSHï¼‰**ï¼š  
     - åŸç†ï¼šå°†ç›¸ä¼¼å‘é‡æ˜ å°„åˆ°ç›¸åŒ"æ¡¶"ä¸­  
     - ä¼˜åŠ¿ï¼šæŸ¥è¯¢æ—¶é—´å¤æ‚åº¦é™è‡³O(1)  

8. **ç»´åº¦ç¾éš¾åº”å¯¹ç­–ç•¥**  

| æ–¹æ³•       | åŸç†         | é€‚ç”¨åœºæ™¯    |
| -------- | ---------- | ------- |
| PCAé™ç»´    | ä¿ç•™æœ€å¤§æ–¹å·®æ–¹å‘   | ç‰¹å¾é«˜åº¦ç›¸å…³æ—¶ |
| t-SNEå¯è§†åŒ– | ä¿æŒå±€éƒ¨ç›¸ä¼¼æ€§    | æ•°æ®æ¢ç´¢é˜¶æ®µ  |
| è‡ªåŠ¨ç¼–ç å™¨    | ç¥ç»ç½‘ç»œå­¦ä¹ ä½ç»´è¡¨ç¤º | å¤æ‚ç‰¹å¾å…³ç³»  |

9. **ç¡¬ä»¶åŠ é€Ÿæ–¹æ¡ˆ**  
   - **GPUå¹¶è¡Œè®¡ç®—**ï¼šä½¿ç”¨CUDAåŠ é€Ÿè·ç¦»çŸ©é˜µè®¡ç®—  
   - **åˆ†å—å¤„ç†**ï¼šå°†å¤§æ•°æ®é›†åˆ†å‰²ä¸ºå¤šä¸ªå­çŸ©é˜µ  
   - **å†…å­˜ä¼˜åŒ–**ï¼š  
     ```python
     # ä½¿ç”¨å†…å­˜æ˜ å°„æ–‡ä»¶å¤„ç†è¶…å¤§æ•°æ®
     X = np.memmap('data.bin', dtype='float32', mode='r', shape=(N, D))
     ```

---

#### **ğŸš¨ KNNçš„è‡´å‘½ç¼ºé™·ä¸æ•‘èµä¹‹é“**
10. **æœ¬è´¨å±€é™æ€§**  
   - **ç†è®ºç¼ºé™·**ï¼š  
     - çªç ´ç‡éšç»´åº¦æŒ‡æ•°ä¸‹é™ï¼ˆCoverå®šç†ï¼‰  
     - é«˜ç»´ç©ºé—´ä¸­ï¼Œæœ€è¿‘é‚»ä¸éšæœºçŒœæµ‹æ— å¼‚  
   - **å®éªŒéªŒè¯**ï¼š  
     ```python
     # é«˜ç»´éšæœºæ•°æ®å®éªŒ
     np.random.seed(42)
     dims = [2, 10, 100, 1000]
     for d in dims:
         X = np.random.randn(1000, d)
         distances = np.sqrt(np.sum((X[0] - X[1:])**2, axis=1))
         print(f"ç»´åº¦{d}: å¹³å‡è·ç¦»={np.mean(distances):.2f}ï¼Œæ ‡å‡†å·®={np.std(distances):.2f}")
     ```

11. **ç°ä»£è§£å†³æ–¹æ¡ˆ**  
   - **æ·±åº¦ç‰¹å¾æå–**ï¼šä½¿ç”¨é¢„è®­ç»ƒCNNæå–é«˜å±‚è¯­ä¹‰ç‰¹å¾  
     ```python
     from torchvision.models import resnet18
     model = resnet18(pretrained=True)
     features_model = torch.nn.Sequential(*list(model.children())[:-1])
     ```
   - **æ··åˆæ¨¡å‹**ï¼šKNN + å†³ç­–æ ‘ï¼ˆKNNé€‰æ‹©å€™é€‰é›†ï¼Œæ ‘æ¨¡å‹ç²¾ç»†åˆ†ç±»ï¼‰  

---

#### **ğŸ› ï¸ KNNæœ€ä½³å®è·µæ£€æŸ¥è¡¨**
12. **é¢„å¤„ç†é˜¶æ®µ**  
   - [ ] åƒç´ å€¼å½’ä¸€åŒ–ï¼ˆå¦‚é™¤ä»¥255ï¼‰  
   - [ ] é€šé“åˆ†ç¦»ï¼ˆRGBåˆ†åˆ«å¤„ç†ï¼‰  
   - [ ] æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬/å¹³ç§»ç”Ÿæˆæ›´å¤šæ ·æœ¬ï¼‰  

13. **ç‰¹å¾å·¥ç¨‹**  
   - [ ] è¾¹ç¼˜æ£€æµ‹ï¼ˆSobelç®—å­ï¼‰  
   - [ ] é¢œè‰²ç›´æ–¹å›¾ç»Ÿè®¡  
   - [ ] çº¹ç†ç‰¹å¾æå–ï¼ˆLBPç®—æ³•ï¼‰  

14. **è¯„ä¼°æŒ‡æ ‡**  
   - **Top-1 Accuracy**ï¼šå¸¸è§„å‡†ç¡®ç‡  
   - **mAPï¼ˆå¹³å‡ç²¾åº¦å‡å€¼ï¼‰**ï¼šè€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡  
   - **æ··æ·†çŸ©é˜µåˆ†æ**ï¼šè¯†åˆ«æ˜“æ··æ·†ç±»åˆ«å¯¹  

```python
# é«˜çº§è¯„ä¼°ç¤ºä¾‹
from sklearn.metrics import classification_report
y_true = [...]  # çœŸå®æ ‡ç­¾
y_pred = [...]  # é¢„æµ‹æ ‡ç­¾
print(classification_report(y_true, y_pred, target_names=class_names))
```

## liner

### **ğŸ“š çº¿æ€§åˆ†ç±»æ·±åº¦è§£æä¸æ‰©å±•æŒ‡å—**

---

#### **ğŸŒŒ æ•°å­¦åŸç†ä¸ç»´åº¦è§£æ**
1. **æ ¸å¿ƒå…¬å¼çš„çŸ©é˜µç»´åº¦è¯¦è§£**  
   $$ f(x,W) = Wx + b $$  
   - **è¾“å…¥**ï¼š$x \in \mathbb{R}^{D}$ï¼ˆå›¾åƒéœ€å±•å¹³ä¸ºå‘é‡ï¼Œå¦‚32x32x3 â†’ 3072ç»´ï¼‰  
   - **æƒé‡çŸ©é˜µ**ï¼š$W \in \mathbb{R}^{C \times D}$ï¼ˆC=ç±»åˆ«æ•°ï¼ŒD=ç‰¹å¾ç»´åº¦ï¼‰  
   - **åç½®é¡¹**ï¼š$b \in \mathbb{R}^{C}$  
   - **è¾“å‡º**ï¼š$s \in \mathbb{R}^{C}$ï¼ˆå„ç±»åˆ«å¾—åˆ†ï¼‰  

   **ç¤ºä¾‹**ï¼š  
   ```python
   # CIFAR-10å›¾åƒåˆ†ç±»ï¼ˆ32x32x3 â†’ 3072ç»´ï¼‰
   x_flatten = x.reshape(3072, 1)          # (3072,1)
   W = np.random.randn(10, 3072)           # (10,3072)
   b = np.random.randn(10, 1)              # (10,1)
   scores = W.dot(x_flatten) + b           # (10,1)
   ```

2. **åç½®é¡¹çš„å‡ ä½•æ„ä¹‰**  
   - **å…è®¸å†³ç­–è¾¹ç•Œå¹³ç§»**ï¼š$Wx + b = 0$ æ˜¯Dç»´ç©ºé—´ä¸­çš„è¶…å¹³é¢  
   - **ç±»åˆ«å¹³è¡¡è°ƒèŠ‚**ï¼šè‹¥æŸç±»æ ·æœ¬è¾ƒå¤šï¼Œå…¶å¯¹åº”åç½®é¡¹ä¼šè‡ªåŠ¨å¢å¤§ï¼ˆéœ€é…åˆæ­£åˆ™åŒ–ï¼‰  
   - **å¯è§†åŒ–æ¡ˆä¾‹**ï¼š  
     ```python
     # äºŒç»´ç©ºé—´å†³ç­–è¾¹ç•Œæ¼”ç¤º
     x = np.linspace(-5,5,100)
     y_decision = (-W[0,0]*x - b[0])/W[0,1]  # W1x + W2y + b =0 â†’ y=(-W1x -b)/W2
     ```

---

#### **ğŸ”¥ æŸå¤±å‡½æ•°å…¨æ™¯è§£æ**
1. **å¤šç±»SVMæŸå¤±ï¼ˆHinge Lossï¼‰**  
   $$ L_i = \sum_{j \neq y_i} \max(0, s_j - s_{y_i} + \Delta) $$  
   - **Î”çš„é€‰æ‹©**ï¼šé€šå¸¸è®¾ä¸º1ï¼Œæ§åˆ¶è¾¹é™…å®½åº¦  
   - **æ¢¯åº¦ç‰¹æ€§**ï¼š  
     - æ­£ç¡®ç±»æ¢¯åº¦ï¼š$-N_{violate}$ï¼ˆN_violateä¸ºè¿åè¾¹é™…çš„æ ·æœ¬æ•°ï¼‰  
     - é”™è¯¯ç±»æ¢¯åº¦ï¼š$\mathbb{I}(s_j - s_{y_i} + \Delta > 0)$  

   **ä»£ç å®ç°**ï¼š  
   ```python
   def svm_loss(scores, y_true, delta=1.0):
       margins = np.maximum(0, scores - scores[y_true] + delta)
       margins[y_true] = 0  # å¿½ç•¥æ­£ç¡®ç±»
       loss = np.sum(margins)
       return loss
   ```

2. **äº¤å‰ç†µæŸå¤±ï¼ˆSoftmaxï¼‰**  
   $$ L_i = -\log\left( \frac{e^{s_{y_i}}}{\sum_j e^{s_j}} \right) $$  
   - **æ¦‚ç‡è§£é‡Š**ï¼š$p_j = \frac{e^{s_j}}{\sum e^{s_k}}$ è¡¨ç¤ºç±»åˆ«æ¦‚ç‡  
   - **æ¢¯åº¦å…¬å¼**ï¼š  
     $$ \frac{\partial L}{\partial s_j} = \begin{cases} p_j - 1 & j = y_i \\ p_j & j \neq y_i \end{cases} $$  

   **æ•°å€¼ç¨³å®šå®ç°**ï¼š  
   ```python
   def softmax_loss(scores, y_true):
       shifted_scores = scores - np.max(scores)  # é˜²æ­¢æŒ‡æ•°çˆ†ç‚¸
       exp_scores = np.exp(shifted_scores)
       probs = exp_scores / np.sum(exp_scores)
       loss = -np.log(probs[y_true])
       return loss
   ```

---

#### **ğŸš€ ä¼˜åŒ–ç®—æ³•æ·±åº¦å‰–æ**
1. **æ¢¯åº¦ä¸‹é™çš„æ•°å­¦æœ¬è´¨**  
   $$ W_{t+1} = W_t - \eta \nabla_W L $$  
   - **å­¦ä¹ ç‡Î·çš„é€‰æ‹©**ï¼š  
     | ç­–ç•¥ | å…¬å¼ | ç‰¹ç‚¹ |  
     |------|------|------|  
     | å›ºå®šå­¦ä¹ ç‡ | Î·=0.01 | ç®€å•ä½†éœ€æ‰‹åŠ¨è°ƒæ•´ |  
     | è‡ªé€‚åº”å­¦ä¹ ç‡ï¼ˆAdaGradï¼‰| $\eta_t = \eta_0 / \sqrt{\sum_{i=1}^t g_i^2}$ | è‡ªåŠ¨è¡°å‡ |  

2. **å‚æ•°æ›´æ–°å¯è§†åŒ–**  
   ```python
   # äºŒç»´å‚æ•°ç©ºé—´ä¸­çš„æ¢¯åº¦ä¸‹é™è½¨è¿¹
   plt.contour(W1, W2, loss_values, levels=50)
   plt.plot(opt_path[:,0], opt_path[:,1], 'r->')
   plt.title("Gradient Descent Optimization Path")
   ```

3. **éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰çš„åŠ é€ŸæŠ€å·§**  
   - **åŠ¨é‡æ³•**ï¼š  
     $$ v_{t+1} = \mu v_t + \eta \nabla_W L $$  
     $$ W_{t+1} = W_t - v_{t+1} $$  
     ï¼ˆÎ¼=0.9æ—¶ï¼Œå¯æœ‰æ•ˆç©¿è¶Šå±€éƒ¨æå°å€¼ï¼‰

---

#### **ğŸ” çº¿æ€§åˆ†ç±»å™¨å±€é™æ€§æ·±åº¦æ¢è®¨**
4. **éçº¿æ€§å¯åˆ†é—®é¢˜çš„æ•°å­¦è¯æ˜**  
   - **XORé—®é¢˜**ï¼šæ— æ³•ç”¨å•å±‚çº¿æ€§åˆ†ç±»å™¨è§£å†³  
     | x1 | x2 | y |  
     |----|----|---|  
     | 0  | 0  | 0 |  
     | 0  | 1  | 1 |  
     | 1  | 0  | 1 |  
     | 1  | 1  | 0 |  

   - **é«˜ç»´ç©ºé—´ä¸­çš„çº¿æ€§ä¸å¯åˆ†æ€§**ï¼š  
     å½“ç±»åˆ«è¾¹ç•Œå‘ˆç°å¤æ‚æ‹“æ‰‘ç»“æ„æ—¶ï¼Œçº¿æ€§åˆ†ç±»å™¨çš„å‡†ç¡®ç‡ä¸Šé™ä¸º50%

5. **å›¾åƒåˆ†ç±»çš„è‡´å‘½ç¼ºé™·**  
   - **æ—‹è½¬ä¸å˜æ€§é—®é¢˜**ï¼š  
     ```python
     rotated_img = scipy.ndimage.rotate(img, 45)
     scores_diff = model.predict(rotated_img) - model.predict(original_img)
     print("åˆ†æ•°å˜åŒ–é‡:", np.linalg.norm(scores_diff))  # é€šå¸¸æå¤§
     ```
   - **éƒ¨åˆ†è§£å†³æ–¹æ¡ˆ**ï¼š  
     - æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬/å¹³ç§»è®­ç»ƒæ ·æœ¬ï¼‰  
     - ç‰¹å¾å·¥ç¨‹ï¼ˆæå–æ—‹è½¬ä¸å˜ç‰¹å¾ï¼‰

---

#### **ğŸ› ï¸ çº¿æ€§åˆ†ç±»å™¨å®æˆ˜è°ƒä¼˜æŒ‡å—**
6. **ç‰¹å¾é¢„å¤„ç†é»„é‡‘æ³•åˆ™**  
   | æ“ä½œ | å…¬å¼ | ä½œç”¨ |  
   |------|------|------|  
   | ä¸­å¿ƒåŒ– | $x' = x - \mu$ | æ¶ˆé™¤åå·® |  
   | å½’ä¸€åŒ– | $x' = \frac{x - \mu}{\sigma}$ | ç»Ÿä¸€é‡çº² |  
   | PCAç™½åŒ– | $x' = \frac{PCA(x)}{\sqrt{\lambda + \epsilon}}$ | å»ç›¸å…³+é™å™ª |  

7. **æ­£åˆ™åŒ–ç­–ç•¥å¯¹æ¯”**  
   | ç±»å‹ | å…¬å¼ | ç‰¹ç‚¹ |  
   |------|------|------|  
   | L2æ­£åˆ™ | $L_{reg} = \lambda \sum W_{ij}^2$ | å¹³æ»‘æƒé‡ |  
   | L1æ­£åˆ™ | $L_{reg} = \lambda \sum |W_{ij}|$ | ç¨€ç–æƒé‡ |  
   | ElasticNet | $L_{reg} = \lambda_1 L1 + \lambda_2 L2$ | å¹³è¡¡æ–¹æ¡ˆ |  

8. **è¶…å‚æ•°æœç´¢ç½‘æ ¼**  
   ```python
   learning_rates = [1e-3, 1e-4, 1e-5]
   reg_strengths = [1e2, 1e3, 1e4]
   best_val_acc = 0
   for lr in learning_rates:
       for reg in reg_strengths:
           model.train(lr, reg)
           val_acc = model.evaluate()
           if val_acc > best_val_acc:
               best_val_acc = val_acc
               best_params = (lr, reg)
   ```

---

#### **ğŸ“Š æ€§èƒ½è¯„ä¼°ä¸å¯è§†åŒ–**
9. **æƒé‡å¯è§†åŒ–æŠ€æœ¯**  
   ```python
   # æ˜¾ç¤ºCIFAR-10å„ç±»åˆ«æ¨¡æ¿
   for i in range(10):
       plt.subplot(2,5,i+1)
       plt.imshow(W[i].reshape(32,32,3))  # åæ ‡å‡†åŒ–å
       plt.title(classes[i])
   plt.show()
   ```
   ![æƒé‡å¯è§†åŒ–](https://cs231n.github.io/assets/imagemap.jpg)

10. **æ··æ·†çŸ©é˜µåˆ†æ**  
   ```python
   from sklearn.metrics import confusion_matrix
   cm = confusion_matrix(y_true, y_pred)
   sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
   plt.xlabel('Predicted')
   plt.ylabel('True')
   ```
   ![æ··æ·†çŸ©é˜µç¤ºä¾‹](https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png)
## loss





