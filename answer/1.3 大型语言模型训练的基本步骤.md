大型语言模型训练的基本步骤。

目前的transformer模型本质上是token接龙，token接龙需要一个有数十亿个参数的函数，而这些参数来源于训练资料，找出来这些参数的过程就是训练。

实际上，语言模型训练的所有阶段都是在做文字接龙，只是训练资料不一样罢了，找参数的过程称之为最佳化，而训练也有可能会失败，这个时候就需要换一种超参数，再来一次。

大型语言模型训练的基本步骤大致有三步，其中的第一阶段是大型语言模型的自我学习，亦称为自督导式学习。在这个阶段，人很少去干预，主要是靠模型自己在网上爬资料进行训练，通过函数的参数量和资料共同训练出语言模型，此阶段称作pre-train。

而在训练的过程中，人需要制作一个过滤网，即过滤有害的内容，去除低品质的资料和去除重复资料。

在这个阶段结束之后，模型仍然没有很好的办法回答问题，是因为模型的本质是在做文字接龙，他根本不知道你输进去的文字是让他干什么的。

此时第一步的训练结束，进入到第二步的训练，人工干预，称之为督导式学习。此时需要耗费人力构筑喂给ai的资料，标注user和ai。这一阶段的训练以第一阶段训练的参数为基础，在pre-train训练的参数之后增加新的参数。

在这一阶段的结束后，ai回答问题的能力大幅度提升，但是他仍然不知道怎样才是回答的好，所以进入第三段，也就是实战——增强式学习。

在这一阶段，需要构筑一个RLHF函数，由他来判断ai生成的答案是否是好的或者坏的。判断可以由人来执行，也可以由ai执行，并通过函数带回来的反馈，进行微调模型的参数，由此来输出更好的答案。

人的判断具有主观性，且人力有限。因此可以使用另一个ai来作为虚拟人类，让ai跟着另一个虚拟人类辅助学习。不过需要注意的是，如果过度使用ai来判断的话，反而会造成生成答案内容品质的下降。